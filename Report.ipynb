{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pose Model Tracking in Babybrain Dataset\n",
    "\n",
    "## Loading COCO-format Annotations\n",
    "We transformed VIA-VGG 3.0.4 Video Annotations to COCO format using mybabybrain-database repository. Now let's load \n",
    "a subset of data from normal and abnormal class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from qol import load_annotations\n",
    "\n",
    "\n",
    "# load annotations\n",
    "annotation_folder = '/home/harrisonford/Documents/babybrain-coco/'\n",
    "normal_set = ['000345']\n",
    "abnormal_set = ['000845']\n",
    "suffix = ''\n",
    "normal_annotations = [load_annotations(annotation_folder + a_file + suffix + '_coco.json') for a_file in normal_set]\n",
    "abnormal_annotations = [load_annotations(annotation_folder + a_file + suffix + '_coco.json') for a_file in abnormal_set]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading video frames \n",
    "Load video frames annotated in files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from qol import times_to_frames, get_frames_from\n",
    "\n",
    "\n",
    "video_folder = '/home/harrisonford/Videos/babybrain/'\n",
    "# extract times (id) to load from annotations, so we can load frames later\n",
    "normal_frames = [[image_dict['id'] for image_dict in annotation['images']] for annotation in normal_annotations]\n",
    "abnormal_frames = [[image_dict['id'] for image_dict in annotation['images']] for annotation in abnormal_annotations]\n",
    "\n",
    "# transform each time id to frame id\n",
    "frame_ids_normal = [times_to_frames(ids) for ids in normal_frames]\n",
    "frame_ids_abnormal = [times_to_frames(ids) for ids in abnormal_frames]\n",
    "\n",
    "# get the frames from video, this takes a while\n",
    "normal_images = [get_frames_from(video_folder + video + '.MP4', frame_list, threshold=1) \n",
    "                          for (video, frame_list) in zip(normal_set, frame_ids_normal)]\n",
    "abnormal_images = [get_frames_from(video_folder + video + '.MP4', frame_list, threshold=1) \n",
    "                            for (video, frame_list) in zip(abnormal_set, frame_ids_abnormal)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using PoseEstimation and HumanPose models on images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[2019-09-25 09:16:49,588] [TfPoseEstimator] [INFO] loading graph from /home/harrisonford/PycharmProjects/mybabybrain-model/PoseEstimation/models/graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I0925 09:16:49.588136 140720066127680 estimator.py:308] loading graph from /home/harrisonford/PycharmProjects/mybabybrain-model/PoseEstimation/models/graph/cmu/graph_opt.pb(default size=432x368)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from poseModels import PoseEstimationModel, HumanPoseModel\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "pose_model = PoseEstimationModel()\n",
    "id_list = []\n",
    "times = []\n",
    "\n",
    "# use pose model\n",
    "for a_video_container, video_ids in zip(normal_images + abnormal_images, normal_frames + abnormal_frames):\n",
    "    for an_image, an_id in zip(a_video_container, video_ids):\n",
    "        tic = timeit.default_timer()\n",
    "        pose_model.outputs.append(pose_model._run_model_once(an_image))\n",
    "        toc = timeit.default_timer()\n",
    "        times.append([toc - tic, 'PoseEst'])\n",
    "        id_list.append(an_id)\n",
    "# save tracking in coco format\n",
    "output_json = '/home/harrisonford/Documents/coco_pose_model.json'\n",
    "pose_model.save_as_coco_result(output_json, id_vector=id_list)\n",
    "\n",
    "# now use the other model\n",
    "tf.reset_default_graph()\n",
    "human_model = HumanPoseModel()\n",
    "for a_video_container, video_ids in zip(normal_images + abnormal_images, normal_frames + abnormal_frames):\n",
    "    for an_image, an_id in zip(a_video_container, video_ids):\n",
    "        tic = timeit.default_timer()\n",
    "        human_model.outputs.append(human_model._run_model_once(an_image))\n",
    "        toc = timeit.default_timer()\n",
    "        times.append([toc - tic, 'HumanPose'])\n",
    "output_json = '/home/harrisonford/Documents/coco_human_model.json'\n",
    "human_model.save_as_coco_result(output_json, id_vector=id_list)\n",
    "\n",
    "# plot avg computation time for each model\n",
    "df = pd.DataFrame(times, columns=['time', 'model'])\n",
    "sns.set(\"paper\")\n",
    "ax = sns.barplot(x='model', y='time', data=df)\n",
    "plt.savefig('/home/harrisonford/Desktop/temp.png', dpi=1000)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Center of Gravity movement\n",
    "\n",
    "Calculating this may give us a hint about the movement patterns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# from the pose model outputs calculate mean center of gravity for each sample\n",
    "center_of_gravities_x = []\n",
    "center_of_gravities_y = []\n",
    "for an_output in pose_model.outputs:\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for a_part in an_output.body_parts.values():  # stack x-y\n",
    "        x_values.append(a_part.x)\n",
    "        y_values.append(a_part.y)\n",
    "    center_of_gravities_x.append(np.mean(x_values))\n",
    "    center_of_gravities_y.append(np.mean(y_values))\n",
    "\n",
    "# now plot it\n",
    "plt.scatter(center_of_gravities_x, center_of_gravities_y, alpha=0.5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking model performances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8232361fc6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# calculate curve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdistances_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible_normal\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnormal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_coco.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdistances_abnormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible_abnormal\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/mybabybrain-model/qol.py\u001b[0m in \u001b[0;36mcompute_error\u001b[0;34m(dt_path, gt_path, normalize, threshold)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# get keypoints as np array from dt and gt and calculate distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgt_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/mybabybrain-model/qol.py\u001b[0m in \u001b[0;36mcompute_error\u001b[0;34m(dt_path, gt_path, normalize, threshold)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# get keypoints as np array from dt and gt and calculate distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgt_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.3519.27/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTATE_SUSPEND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m                     \u001b[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.3519.27/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# IFDEF CYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.3519.27/helpers/pydev/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.3519.27/helpers/pydev/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "from qol import compute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# calculate curve performance\n",
    "distances_normal, visible_normal = \\\n",
    "    compute_error(output_json, annotation_folder + normal_set[0] + suffix +'_coco.json', normalize='body')\n",
    "\n",
    "distances_abnormal, visible_abnormal = \\\n",
    "    compute_error(output_json, annotation_folder + abnormal_set[0] + suffix + '_coco.json', normalize='body')\n",
    "\n",
    "# for each detection threshold count the data that falls in, for each joint\n",
    "threshold = np.array(range(101))/100\n",
    "threshold_total_count_normal = []\n",
    "threshold_total_count_abnormal = []\n",
    "for a_threshold in threshold:  # count for each threshold\n",
    "    threshold_count_normal = np.zeros(distances_normal[0].shape)\n",
    "    threshold_count_abnormal = np.zeros(distances_abnormal[0].shape)\n",
    "    for a_sample_distance in distances_normal:  # accumulate from all samples\n",
    "        for index, a_joint_distance in enumerate(a_sample_distance):  # for each joint\n",
    "            if a_joint_distance <= a_threshold:\n",
    "                threshold_count_normal[index] += 1\n",
    "    for a_sample_distance in distances_abnormal:  # accumulate from all samples\n",
    "        for index, a_joint_distance in enumerate(a_sample_distance):  # for each joint\n",
    "            if a_joint_distance <= a_threshold:\n",
    "                threshold_count_abnormal[index] += 1\n",
    "    threshold_total_count_normal.append(threshold_count_normal)\n",
    "    threshold_total_count_abnormal.append(threshold_count_abnormal)\n",
    "\n",
    "# finally normalize by quantity\n",
    "threshold_total_count_normal = [count_sample / len(normal_frames[0]) \n",
    "                                for count_sample in threshold_total_count_normal]\n",
    "threshold_total_count_abnormal = [count_sample / len(abnormal_frames[0]) \n",
    "                                  for count_sample in threshold_total_count_abnormal]\n",
    "# save in a data frame so it's easier to plot\n",
    "data = []\n",
    "left_mask = [0, 1, 5, 6, 7, 11, 12, 13, 15, 17]\n",
    "right_mask = [0, 1, 2, 3, 4, 8, 9, 10, 14, 16]\n",
    "graph_type = 'class'\n",
    "mask_type = 'left'\n",
    "for threshold_index, a_threshold in enumerate(threshold_total_count_normal):\n",
    "    for joint_index, a_value in enumerate(a_threshold):\n",
    "        if joint_index not in right_mask and graph_type == 'joint' and mask_type == 'right':\n",
    "            continue\n",
    "        if joint_index not in left_mask and graph_type == 'joint' and mask_type == 'left':\n",
    "            continue\n",
    "        data.append([threshold[threshold_index], joint_index, a_value, 'normal'])\n",
    "for threshold_index, a_threshold in enumerate(threshold_total_count_abnormal):\n",
    "    for joint_index, a_value in enumerate(a_threshold):\n",
    "        if joint_index not in right_mask and graph_type == 'joint' and mask_type == 'right':\n",
    "            continue\n",
    "        if joint_index not in left_mask and graph_type == 'joint' and mask_type == 'left':\n",
    "            continue\n",
    "        data.append([threshold[threshold_index], joint_index, a_value, 'abnormal'])\n",
    "df = pd.DataFrame(data=data, columns=['threshold', 'joint', 'ratio', 'class'])\n",
    "sns.set(\"paper\")\n",
    "ax = sns.lineplot(x='threshold', y='ratio', data=df, hue=graph_type, palette='Paired')  # use hue=joint or class to change fig\n",
    "plt.tight_layout()\n",
    "if graph_type == 'joint':  # make custom legend\n",
    "    joint_names = ['Nose', 'Neck', 'Shoulder', 'Elbow', 'Wrist', 'Hip', 'Knee', 'Ankle', 'Eye', 'Ear']\n",
    "    plt.legend(title='Joint', labels=joint_names, loc='lower right', fontsize='x-small')\n",
    "plt.savefig('/home/harrisonford/Desktop/temp.png', dpi=1000)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Confidence as Class Features\n",
    "A fast way of classifying movement is by using confidence value outputs as some sort of\n",
    "Transfer Learning approach, therefore we explore confidence values through different class\n",
    "separations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# read normal and abnormal confidence data\n",
    "normal_path = './'\n",
    "normal_df = pd.read_csv(normal_path)\n",
    "abnormal_path = './'\n",
    "abnormal_df = pd.read_csv(abnormal_path)\n",
    "\n",
    "# plot bars normal vs abnormal\n",
    "plt.figure()\n",
    "wid = 0.25\n",
    "plt.bar(np.arange(normal_df))  # TODO: Continue!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}